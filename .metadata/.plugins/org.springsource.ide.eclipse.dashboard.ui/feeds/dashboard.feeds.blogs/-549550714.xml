<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Spring]]></title><description><![CDATA[Level up your Java code and explore what Spring can do for you.]]></description><link>https://spring.io</link><generator>GatsbyJS</generator><lastBuildDate>Wed, 04 Oct 2023 07:43:55 GMT</lastBuildDate><item><title><![CDATA[Spring Shell 2.1.13, 3.0.8 and 3.1.4 are now available]]></title><link>https://spring.io/blog/2023/10/04/spring-shell-2-1-13-3-0-8-and-3-1-4-are-now-available</link><guid isPermaLink="true">https://spring.io/blog/2023/10/04/spring-shell-2-1-13-3-0-8-and-3-1-4-are-now-available</guid><dc:creator><![CDATA[Janne Valkealahti]]></dc:creator><pubDate>Wed, 04 Oct 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Spring Shell 2.1.13, 3.0.8 and 3.1.4 are now available&lt;/p&gt;
&lt;p&gt;On behalf of the team and everyone who has contributed, I&apos;m happy to announce that Spring Shell &lt;code&gt;2.1.13&lt;/code&gt;, &lt;code&gt;3.0.8&lt;/code&gt; and &lt;code&gt;3.1.4&lt;/code&gt; has been released and are now available from Maven Central.&lt;/p&gt;
&lt;p&gt;Please see the &lt;a href=&quot;https://github.com/spring-projects/spring-shell/releases/tag/v2.1.13&quot;&gt;release notes 2.1.13&lt;/a&gt;, &lt;a href=&quot;https://github.com/spring-projects/spring-shell/releases/tag/v3.0.8&quot;&gt;release notes 3.0.8&lt;/a&gt; and &lt;a href=&quot;https://github.com/spring-projects/spring-shell/releases/tag/v3.1.4&quot;&gt;release notes 3.1.4&lt;/a&gt; for more details.&lt;/p&gt;
&lt;p&gt;Thanks to all those who have contributed with issue reports and pull requests.&lt;/p&gt;
&lt;h3 id=&quot;how-can-you-help&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#how-can-you-help&quot; aria-label=&quot;how can you help permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How can you help?&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://spring.io/projects/spring-shell/&quot;&gt;Project Page&lt;/a&gt; | &lt;a href=&quot;https://github.com/spring-projects/spring-shell&quot;&gt;GitHub&lt;/a&gt; | &lt;a href=&quot;https://github.com/spring-projects/spring-shell/issues&quot;&gt;Issues&lt;/a&gt; | &lt;a href=&quot;https://docs.spring.io/spring-shell/docs/3.1.4/docs/index.html&quot;&gt;Documentation&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[This Week in Spring - October 3rd, 2023]]></title><link>https://spring.io/blog/2023/10/03/this-week-in-spring-october-3rd-2023</link><guid isPermaLink="true">https://spring.io/blog/2023/10/03/this-week-in-spring-october-3rd-2023</guid><dc:creator><![CDATA[Josh Long]]></dc:creator><pubDate>Tue, 03 Oct 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Hi Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! How&apos;re you doin&apos;? I&apos;ve just flown in from Singapore - where I was keynoting and presenting at SpringOne Singapore - and am now in Antwerp, Belgium for the deliriously fun Devoxx Belgium show. I&apos;ve missed this show, and it&apos;s a true pleasure to be back here! Next week, I&apos;ll be in Amsterdam, just next door, for the SpringOne Tour Amsterdam. If you&apos;re there, come out and say hi!&lt;/p&gt;
&lt;p&gt;We&apos;ve got a lot of stuff to look at this morning, so let&apos;s dive right into it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://spring.io/blog/2023/09/28/a-bootiful-podcast-spring-ai-lead-dr-mark-pollack&quot;&gt;A Bootiful Podcast: Spring AI lead Dr. Mark Pollack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=bbzek2j3Yz0&quot;&gt;Building a ChatGPT clone with Spring Boot, LangChain, and React in 20 minutes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/@anilfromdit/dockerize-your-spring-boot-app-like-a-pro-d1dd0ef37b79&quot;&gt;Dockerize Your Spring Boot App Like a Pro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hah. This is fun! &lt;a href=&quot;https://www.youtube.com/watch?v=0QVdJcxGf1M&quot;&gt;Generate Dynamic Websites using ChatGPT and Spring AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;a new release of &lt;a href=&quot;https://github.com/toedter/spring-hateoas-jsonapi&quot;&gt;GitHub - toedter/spring-hateoas-jsonapi: A JSON:API media type implementation for Spring HATEOAS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=74AEVZOBL88&quot;&gt;How To Log Outgoing HTTP Requests with Spring Rest Client and Spring Boot 3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://spring.io/blog/2023/09/27/introduction-to-transactions-in-spring-cloud-stream-kafka-applications&quot;&gt;Introduction to Transactions in Spring Cloud Stream Kafka Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://spring.io/blog/2023/09/29/spring-cloud-2023-0-0-m2-aka-leyton-has-been-released&quot;&gt;Spring Cloud 2023.0.0-M2 (aka Leyton) has been released&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://x.com/jimgris/status/1707824816835932410?s=12&amp;#x26;t=n-UflcIbnx1lage-TBk0Cg&quot;&gt;I&apos;ll be in Switzerland next week as well, and one of the people I am most looking forward to seeing is my friend Sam Brannen, major contributor to the JUnit project and lead of the Spring testing efforts. If you can&apos;t be there with us, you should enjoy this wonderful discussion between him and Oracle&apos;s Jim Grisanzio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://x.com/odrotbohm/status/1707038889909641224?s=12&amp;#x26;t=n-UflcIbnx1lage-TBk0Cg&quot;&gt;this is super cool: Spring Modulith made it into the Thoughtworks Technology Radar&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://kubernetes.io/blog/2023/10/02/steering-committee-results-2023/&quot;&gt;Blog: Announcing the 2023 Steering Committee Election Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://kubernetes.io/blog/2023/09/26/happy-7th-birthday-kubeadm/&quot;&gt;Blog: Happy 7th Birthday kubeadm!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Spring Cloud 2023.0.0-M2 (aka Leyton) has been released]]></title><link>https://spring.io/blog/2023/09/29/spring-cloud-2023-0-0-m2-aka-leyton-has-been-released</link><guid isPermaLink="true">https://spring.io/blog/2023/09/29/spring-cloud-2023-0-0-m2-aka-leyton-has-been-released</guid><dc:creator><![CDATA[Olga Maciaszek-Sharma]]></dc:creator><pubDate>Fri, 29 Sep 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;On behalf of the community, I am pleased to announce that the Milestone 2 (M2) of the &lt;a href=&quot;https://cloud.spring.io&quot;&gt;Spring Cloud 2023.0&lt;/a&gt; Release Train is available today. The release can be found in &lt;a href=&quot;https://repo.spring.io/milestone/&quot;&gt;Spring Milestone&lt;/a&gt; repository. You can check out the 2023.0 &lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2023.0-Release-Notes&quot;&gt;release notes for more information&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;notable-changes-in-the-202300-m2-release-train&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#notable-changes-in-the-202300-m2-release-train&quot; aria-label=&quot;notable changes in the 202300 m2 release train permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Notable Changes in the 2023.0.0-M2 Release Train&lt;/h2&gt;
&lt;p&gt;In this milestone, we have migrated the documentation of all the Spring Cloud projects to Antora.&lt;/p&gt;
&lt;p&gt;See all issues and pull requests &lt;a href=&quot;https://github.com/orgs/spring-cloud/projects/117/views/1&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;spring-cloud-commons&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#spring-cloud-commons&quot; aria-label=&quot;spring cloud commons permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spring Cloud Commons&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Refresh Scope on restart - a feature tailored to allow adapting to environment changes on JVM Checkpoint-Restart (&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-commons/pull/1266&quot;&gt;PR 1266&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;spring-cloud-gateway&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#spring-cloud-gateway&quot; aria-label=&quot;spring cloud gateway permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spring Cloud Gateway&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Specify &lt;code&gt;clientRegistrationId&lt;/code&gt; in &lt;code&gt;TokenRelay&lt;/code&gt; filter. (&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-gateway/pull/2922&quot;&gt;PR 2922&lt;/a&gt;) The gateway can be used to manage many ClientRegistrations, and each route can determine which client registration to use. This is incredibly useful in scenarios where there are (for example):
&lt;ul&gt;
&lt;li&gt;multiple authorization servers in use simultaneously.&lt;/li&gt;
&lt;li&gt;multiple client authentication methods in use simultaneously.&lt;/li&gt;
&lt;li&gt;some/all downstream services require a distinct clientId, aud claim, etc.&lt;/li&gt;
&lt;li&gt;some/all downstream services require different token formats (e.g. JWT, opaque)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;spring-cloud-openfeign&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#spring-cloud-openfeign&quot; aria-label=&quot;spring cloud openfeign permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spring Cloud OpenFeign&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Upgraded to Feign 12.5 (&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-openfeign/pull/907&quot;&gt;PR_907&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;spring-cloud-task&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#spring-cloud-task&quot; aria-label=&quot;spring cloud task permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spring Cloud Task&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Users now have the ability to query for task executions using the external execution id. (&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-task/issues/863&quot;&gt;PR_863&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;spring-cloud-function&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#spring-cloud-function&quot; aria-label=&quot;spring cloud function permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spring Cloud Function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Users now have the ability to deploy REST applications as &lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-function/tree/main/spring-cloud-starter-function-web&quot;&gt;AWS Lambdas or Azure Functions&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CRUD mappings for functions deployed as REST endpoints via &lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-function/issues/1025&quot;&gt;spring-cloud-function-web&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;spring-cloud-stream&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#spring-cloud-stream&quot; aria-label=&quot;spring cloud stream permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spring Cloud Stream&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Several important &lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-stream/milestone/89?closed=1&quot;&gt;bug fixes and enhancements&lt;/a&gt; primarily related to Apache Kafka binders and new Apache Pulsar binder.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following modules were updated as part of 2023.0.0-M2:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Module&lt;/th&gt;
&lt;th&gt;Version&lt;/th&gt;
&lt;th&gt;Issues&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Consul&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-consul/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Gateway&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-gateway/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Zookeeper&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-zookeeper/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Bus&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-bus/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Stream&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-stream/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Function&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-function/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud OpenFeign&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-openfeign/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Vault&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-vault/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Commons&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-commons/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Task&lt;/td&gt;
&lt;td&gt;3.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-task/releases/tag/v3.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Kubernetes&lt;/td&gt;
&lt;td&gt;3.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-kubernetes/releases/tag/v3.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Starter Build&lt;/td&gt;
&lt;td&gt;2023.0.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-starter-build/releases/tag/v2023.0.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Config&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-config/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Build&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-build/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Netflix&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-netflix/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud CircuitBreaker&lt;/td&gt;
&lt;td&gt;3.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-circuitbreaker/releases/tag/v3.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Contract&lt;/td&gt;
&lt;td&gt;4.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-contract/releases/tag/v4.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spring Cloud Task&lt;/td&gt;
&lt;td&gt;3.1.0-M2&lt;/td&gt;
&lt;td&gt;(&lt;a href=&quot;https://github.com/spring-cloud/spring-cloud-contract/releases/tag/v3.1.0-M2&quot;&gt;issues&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As always, we welcome feedback on &lt;a href=&quot;https://github.com/spring-cloud/&quot;&gt;GitHub&lt;/a&gt;, on &lt;a href=&quot;https://stackoverflow.com/questions/tagged/spring-cloud&quot;&gt;Stack Overflow&lt;/a&gt;, or on &lt;a href=&quot;https://twitter.com/SpringCloud&quot;&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get started with Maven with a BOM (dependency management only):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;#x3C;repositories&gt;
    &amp;#x3C;repository&gt;
        &amp;#x3C;id&gt;spring-milestones&amp;#x3C;/id&gt;
        &amp;#x3C;name&gt;Spring Milestones&amp;#x3C;/name&gt;
        &amp;#x3C;url&gt;https://repo.spring.io/milestone&amp;#x3C;/url&gt;
        &amp;#x3C;snapshots&gt;
            &amp;#x3C;enabled&gt;false&amp;#x3C;/enabled&gt;
        &amp;#x3C;/snapshots&gt;
    &amp;#x3C;/repository&gt;
&amp;#x3C;/repositories&gt;
&amp;#x3C;dependencyManagement&gt;
    &amp;#x3C;dependencies&gt;
        &amp;#x3C;dependency&gt;
            &amp;#x3C;groupId&gt;org.springframework.cloud&amp;#x3C;/groupId&gt;
            &amp;#x3C;artifactId&gt;spring-cloud-dependencies&amp;#x3C;/artifactId&gt;
            &amp;#x3C;version&gt;2023.0.0-M2&amp;#x3C;/version&gt;
            &amp;#x3C;type&gt;pom&amp;#x3C;/type&gt;
            &amp;#x3C;scope&gt;import&amp;#x3C;/scope&gt;
        &amp;#x3C;/dependency&gt;
    &amp;#x3C;/dependencies&gt;
&amp;#x3C;/dependencyManagement&gt;
&amp;#x3C;dependencies&gt;
    &amp;#x3C;dependency&gt;
        &amp;#x3C;groupId&gt;org.springframework.cloud&amp;#x3C;/groupId&gt;
        &amp;#x3C;artifactId&gt;spring-cloud-starter-config&amp;#x3C;/artifactId&gt;
    &amp;#x3C;/dependency&gt;
    &amp;#x3C;dependency&gt;
        &amp;#x3C;groupId&gt;org.springframework.cloud&amp;#x3C;/groupId&gt;
        &amp;#x3C;artifactId&gt;spring-cloud-starter-netflix-eureka-client&amp;#x3C;/artifactId&gt;
    &amp;#x3C;/dependency&gt;
    ...
&amp;#x3C;/dependencies&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or with Gradle:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-groovy&quot;&gt;plugins {
  id &apos;java&apos;
  id &apos;org.springframework.boot&apos; version &apos;3.2.0-M3&apos;
  id &apos;io.spring.dependency-management&apos; version &apos;1.1.3&apos;
}

group = &apos;com.example&apos;
version = &apos;0.0.1-SNAPSHOT&apos;

java {
  sourceCompatibility = &apos;17&apos;
}

repositories {
  mavenCentral()
  maven { url &apos;https://repo.spring.io/milestone&apos; }
}

ext {
  set(&apos;springCloudVersion&apos;, &quot;2023.0.0-M2&quot;)
}

dependencies {
  implementation &apos;org.springframework.cloud:spring-cloud-starter-config&apos;
  implementation &apos;org.springframework.cloud:spring-cloud-starter-netflix-eureka-client&apos;
  testImplementation &apos;org.springframework.boot:spring-boot-starter-test&apos;
}

dependencyManagement {
  imports {
    mavenBom &quot;org.springframework.cloud:spring-cloud-dependencies:${springCloudVersion}&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;</content:encoded></item><item><title><![CDATA[Producer Initiated Transactions in Spring Cloud Stream Kafka Applications]]></title><link>https://spring.io/blog/2023/09/28/producer-initiated-transactions-in-spring-cloud-stream-kafka-applications</link><guid isPermaLink="true">https://spring.io/blog/2023/09/28/producer-initiated-transactions-in-spring-cloud-stream-kafka-applications</guid><dc:creator><![CDATA[Soby Chacko]]></dc:creator><pubDate>Thu, 28 Sep 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;strong&gt;Other parts in this blog series&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Part 1: &lt;a href=&quot;https://spring.io/blog/2023/09/27/introduction-to-transactions-in-spring-cloud-stream-kafka-applications&quot;&gt;Introduction to Transactions in Spring Cloud Stream Kafka Applications&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This article is part 2 of the blog series in which we look at transactions in detail with Spring Cloud Stream and Apache Kafka. We saw a general introduction to transactions in the &lt;a href=&quot;https://spring.io/blog/2023/09/27/introduction-to-transactions-in-spring-cloud-stream-kafka-applications&quot;&gt;previous part&lt;/a&gt;, touching on the fundamental ideas. In this part of the blog series, we get to the metal by seeing a few implementation details and their practical aspects.&lt;/p&gt;
&lt;p&gt;In this article, we largely stay on the producer&apos;s side to understand how transactions work with Spring Cloud Stream and Apache Kafka.&lt;/p&gt;
&lt;h2 id=&quot;producers-in-spring-cloud-stream&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#producers-in-spring-cloud-stream&quot; aria-label=&quot;producers in spring cloud stream permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Producers in Spring Cloud Stream&lt;/h2&gt;
&lt;p&gt;Before we look deeper into producer-initiated transactions, let¡¯s get to some basics by looking at a simple producer. In Spring Cloud Stream, there are a couple of ways to write a producer (also known as a publisher in the messaging domain). If you have a use case in which you need to produce data on a schedule, you can write a &lt;code&gt;java.util.function.Supplier&lt;/code&gt; method as shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Bean
public Supplier&amp;#x3C;Pojo&gt; mySupplier() {
  return () -&gt; {
        new Pojo();
  };
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When providing the above Supplier as a Spring bean, as indicated in the code, Spring Cloud Stream treats it as a publisher, and, since we are under the context of Apache Kafka here, it sends the POJO record to a Kafka topic.&lt;/p&gt;
&lt;p&gt;By default, Spring Cloud Stream invokes the supplier once each second, but you can change that schedule through configuration. See the &lt;a href=&quot;https://docs.spring.io/spring-cloud-stream/docs/current/reference/html/spring-cloud-stream.html#_polling_configuration_properties&quot;&gt;refence docs&lt;/a&gt; fore more details.&lt;/p&gt;
&lt;p&gt;What if you don¡¯t want to poll the supplier but want to control how often it publishes? Spring Cloud Stream provides a convenient way through the &lt;code&gt;StreamOperations&lt;/code&gt; API with its out-of-the-box implementation called &lt;code&gt;StreamBridge&lt;/code&gt;. Here is an example.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Autowired
StreamBridge streamBridge;

@PostMapping(&quot;/send-data&quot;)
public void publishData() {
   streamBridge.send(&quot;mySupplier-out-0&quot;, new Pojo());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, the application uses a REST endpoint to trigger publishing the data through &lt;code&gt;StreamBridge&lt;/code&gt;. Since the framework does not call the function on a schedule, any external party can initiate the publishing of the data by invoking the REST endpoint.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Is it Appropriate to Use Transactions in These Basic Producers?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now that we have seen the two strategies Spring Cloud Stream provides for publishing records, let us return to our main topic of discussion: &lt;strong&gt;transactional publishing&lt;/strong&gt;.
Assume a scenario in which we want to ensure data integrity and gain transactional guarantees while using one or more of these producers. In that case, the question is whether we need to use transactions to achieve them in the first place. In these two examples above, how can you ensure that the records are published transactionally? The short answer is that you should refrain from using transactions for these types of publishing use cases. The publishing of the records in these examples are single-send scenarios. Using a sync producer, we can achieve the same semantic transactional guarantees. By default, the producer is asynchronous, and, when making it run in synchronous mode, the producer ensures that it writes the records to the leader and all the replicas before sending a response to the client. You can enable sync publishing by setting the &lt;code&gt;spring.cloud.stream.kafka.bindings.&amp;#x3C;binding-name&gt;.producer.sync&lt;/code&gt; property to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To summarize, when designing a producer-only application, use transactions judiciously. We do not recommend using transactions if you send one record at a time by using a &lt;code&gt;Supplier&lt;/code&gt; or through &lt;code&gt;StreamBridge&lt;/code&gt;, since converting the producer to run in sync mode would accomplish the same result without the transaction overhead. This discussion then leads to an interesting question. For producer-only applications, when does it become necessary to use transactions and get the benefits? As discussed in the &lt;a href=&quot;https://spring.io/blog/2023/09/27/introduction-to-transactions-in-spring-cloud-stream-kafka-applications&quot;&gt;previous part&lt;/a&gt; of this blog series, it depends entirely on the application&apos;s use case. In the context of producers, this means that we need only use transactions if we do multiple related publishings, or, in addition to publishing, we need to synchronize with an external transaction manager. The next sections of this post cover the former scenario, and the next post in this blog series covers the latter one.&lt;/p&gt;
&lt;h2 id=&quot;enabling-transactions-in-spring-cloud-stream-kafka-binder&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#enabling-transactions-in-spring-cloud-stream-kafka-binder&quot; aria-label=&quot;enabling transactions in spring cloud stream kafka binder permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Enabling Transactions in Spring Cloud Stream Kafka Binder&lt;/h2&gt;
&lt;p&gt;The main driver for enabling transactions in the Kafka binder for Spring Cloud Stream is a single property:  &lt;code&gt;spring.cloud.stream.kafka.binder.transaction.transaction-id-prefix&lt;/code&gt;. When this property has a valid prefix string, the Kafka binder in Spring Cloud Stream ensures that the underlying &lt;code&gt;KafkaTemplate&lt;/code&gt; publishes the data by using transactions. Incidentally, this property signals Spring Cloud Stream to make a consumer be transaction-aware while using processor patterns (&lt;strong&gt;consume-process-produce&lt;/strong&gt; or &lt;strong&gt;read-process-write&lt;/strong&gt; patterns).&lt;/p&gt;
&lt;h2 id=&quot;transactions-in-action&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#transactions-in-action&quot; aria-label=&quot;transactions in action permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transactions in Action&lt;/h2&gt;
&lt;p&gt;Although counterintuitive, let us return to our single &lt;code&gt;Supplier&lt;/code&gt; or &lt;code&gt;StreamBridge&lt;/code&gt; example (described earlier) and introduce transactions to understand the primary usage of transaction components. As explained earlier, we need not use transactions in those cases, as this adds more overhead. However, doing so helps us understand things.&lt;/p&gt;
&lt;p&gt;Here is the code again:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@SpringBootApplication
@RestController
public class SimpleSpringCloudStreamProducer {

  @Bean
  public Supplier&amp;#x3C;Pojo&gt; mySupplier() {
    return () -&gt; {
      new Pojo();
    };
  }

  @Autowired
  StreamBridge streamBridge;

  @PostMapping(&quot;/send-data&quot;)
  public void publishData() {
   streamBridge.send(&quot;mySupplier-out-0&quot;, new Pojo());
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let us now provide the required property.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spring.cloud.stream.kafka.binder.transaction.transaction-id-prefix: my-transactional-producer-
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since we are providing the property in the application¡¯s configuration, each time the supplier in this example is invoked (through the framework) or someone calls the REST endpoint behind the &lt;code&gt;StreamBridge#send&lt;/code&gt; method, the underlying publishing to Kafka topic becomes fully transactional.&lt;/p&gt;
&lt;p&gt;When the supplier is triggered, the Kafka binder uses a &lt;code&gt;KafkaTemplate&lt;/code&gt; to publish the data. When the binder detects that the application provides the &lt;code&gt;transaction-id-prefix&lt;/code&gt; property, each &lt;code&gt;KafkaTemplate#send&lt;/code&gt; invocation is done through the &lt;code&gt;KafkaTemplate#executeInTransaction&lt;/code&gt; method. Thus, rest assured that the frameworks do the underlying publishing to the Kafka topic transactionally. From an application perspective, the only thing the app developer needs to provide for transaction purposes is the &lt;code&gt;transaction-id-prefix&lt;/code&gt; property.&lt;/p&gt;
&lt;p&gt;Setting the logging level to &lt;code&gt;TRACE&lt;/code&gt; is often worthwhile when developing or debugging transactional applications so that the relevant underlying transactional classes can provide us with details about what¡¯s happening.&lt;/p&gt;
&lt;p&gt;For example, if you set the logging level to TRACE on the following packages, you will see quite a lot of activity in the logs.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;logging:
 level:
   org.springframework.transaction: TRACE
   org.springframework.kafka.transaction: TRACE
   org.springframework.kafka.producer: TRACE
   org.springframework.kafka.core: TRACE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can observe the following in the logs each time the framework calls the supplier method:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;o.s.k.core.DefaultKafkaProducerFactory   : CloseSafeProducer [delegate=org.apache.kafka.clients.producer.KafkaProducer@1426370c] beginTransaction()
o.s.kafka.core.KafkaTemplate             : Sending: ProducerRecord
o.s.kafka.core.KafkaTemplate             : Sent: ProducerRecord(topic=myTopic1, partition=null, headers=RecordHeaders(headers = ¡¦
o.s.k.core.DefaultKafkaProducerFactory   : CloseSafeProducer [delegate=org.apache.kafka.clients.producer.KafkaProducer@1426370c] commitTransaction()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see from the trace logs, each time it publishes the record transactionally, it forms a sequence: &lt;strong&gt;beginTransaction&lt;/strong&gt;, &lt;strong&gt;Sending&lt;/strong&gt;, &lt;strong&gt;Sent&lt;/strong&gt;, and &lt;strong&gt;commitTransaction&lt;/strong&gt;. If you run the application, you will observe that you see these sequences every second since that is the default schedule for how often Spring Cloud Stream invokes a &lt;code&gt;Supplier&lt;/code&gt; method.&lt;/p&gt;
&lt;p&gt;The same transactional flow applies to the &lt;code&gt;StreamBridge#send&lt;/code&gt; case also. When Spring Cloud Stream calls the send method, the underlying &lt;code&gt;KafkaTemplate&lt;/code&gt; that the output binding uses ensures that the record publishes within a transaction, since we provide the &lt;code&gt;transaction-id-prefix&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;transactions-with-multiple-record-publishing&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#transactions-with-multiple-record-publishing&quot; aria-label=&quot;transactions with multiple record publishing permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transactions with multiple record publishing&lt;/h2&gt;
&lt;p&gt;With that primer out of the way, let¡¯s move on to cases where it makes sense to use transactions. As we discussed before, the need to publish multiple records as a single atomic unit is a valid scenario where using transactions becomes necessary.&lt;/p&gt;
&lt;p&gt;Let¡¯s look at the following code example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public void publish(StreamBridge streamBridge {
  for (int i = 0; i &amp;#x3C; 5; i++) {
    streamBridge.send(&quot;mySupplier-out-0&quot;, &quot;data-&quot; + i);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this is a contrived example to demonstrate what is at stake. Instead of publishing once, we publish multiple records. Publishing to multiple topics is also an equally valid approach here. We might think that we can quickly wrap the publishing of multiple records within a single transaction by setting the &lt;code&gt;transaction-id-prefix&lt;/code&gt; property. However, we need more than this to help us here. We still need to provide the prefix property. However, with just that, each send still occurs in its dedicated transaction. To ensure that the whole end-to-end publishing of all five records happens atomically, we need to apply the &lt;code&gt;@Transactional&lt;/code&gt; annotation from the core Spring Framework on the method. In addition, we must provide a transaction manager bean - &lt;code&gt;KafkaTransactionManager&lt;/code&gt; -  that uses the same producer factory created by the Spring Cloud Stream Kafka binder. Here is how our code looks like now and the application&apos;s configuration:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@SpringBootApplication
@RestController
public class SpringCloudStreamProducer {

   @Autowired
   StreamBridge streamBridge;

   @Autowired Sender sender;

   @Autowired
   DefaultBinderFactory binderFactory;

   public static void main(String[] args) {
       SpringApplication.run(SpringCloudStreamProducer.class, args);
   }

   @PostMapping(&quot;/send-data&quot;)
   public void publishData() throws InterruptedException {
       sender.send(streamBridge);
   }

   @Component
   static class Sender {

     @Transactional        
     public void send(StreamBridge streamBridge)      
     {
       for (int i = 0; i &amp;#x3C; 5; i++) {
     	   streamBridge.send(&quot;mySupplier-out-0&quot;, &quot;data-&quot; + i);           
       }
     }
   }

  @Bean
  KafkaTransactionManager customKafkaTransactionManager() {
     KafkaMessageChannelBinder kafka = (KafkaMessageChannelBinder)this.binderFactory.getBinder(&quot;kafka&quot;, MessageChannel.class);
     ProducerFactory&amp;#x3C;byte[], byte[]&gt; transactionalProducerFactory = kafka.getTransactionalProducerFactory();
     KafkaTransactionManager kafkaTransactionManager = new KafkaTransactionManager(transactionalProducerFactory);
     return kafkaTransactionManager;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the corresponding configuration:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spring:
  cloud:
   stream:
     bindings:
       mySupplier-out-0:
         destination: my-topic
     kafka:
       binder:
         Transaction:
		transaction-id-prefix: mySupplier-
producer:
             configuration:
               retries: 1
               acks: all
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the transactional method (the method annotated with &lt;code&gt;@Transactional&lt;/code&gt;) in the preceding code must be in a different class from the one invoking the method. If the invocation is between the methods on the same class or between different classes that are not Spring-managed beans, there is no proxy, and the transaction interceptor does not kick in. The JVM does not know about the proxying and interceptor mechanism at runtime. When adding the &lt;code&gt;@Transactional&lt;/code&gt; annotation on a method, Spring creates a transactional proxy for that method behind the scenes. When Spring Cloud Stream invokes the transactional method, the proxy intercepts that call and then the actual invocation happens through the proxied object.&lt;/p&gt;
&lt;p&gt;The custom &lt;code&gt;KafkaTransactionManager&lt;/code&gt; bean we provide serves two purposes. First, it makes Spring Boot apply &lt;code&gt;@EnableTransactionManagerment&lt;/code&gt;. It also provides the same producer factory the binder uses internally so that the Transactional annotation uses the proper resources when applying transactions.&lt;/p&gt;
&lt;p&gt;When Spring Boot detects an available transaction manager bean, it automatically applies the &lt;code&gt;@EnableTransactionManagement&lt;/code&gt; annotation for us, which is responsible for detecting the &lt;code&gt;@Transactional&lt;/code&gt; annotation and then adding the interceptor through the Spring AOP proxy and advice mechanism. In other words, Spring AOP creates a proxy for the &lt;code&gt;@Transactional&lt;/code&gt; method and includes the AOP advice. Without the &lt;code&gt;@EnableTransactionManagement&lt;/code&gt; annotation applied, Spring does not trigger any of these proxying and interception mechanisms. Since the &lt;code&gt;EnableTransactionManagement&lt;/code&gt; annotation is crucial for these various reasons, we must provide a transaction manager bean. Otherwise, the &lt;code&gt;Transactional&lt;/code&gt; annotation on the method has no bearings.&lt;/p&gt;
&lt;p&gt;Note that we are getting the transactional producer factory from the binder and using that in the constructor for &lt;code&gt;KafkaTransactionManager&lt;/code&gt;. When this bean is present in the application, the entire publishing of all the records now happens within the scope of a single transaction. We see only a single sequence of &lt;strong&gt;beginTransaction¡¦commitTransaction&lt;/strong&gt; in the trace logs, which means that only one proper transaction carries out all the publishing operations.&lt;/p&gt;
&lt;p&gt;Behind the scenes, these are the sequence of events:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;As soon as the method annotated with &lt;code&gt;Transactional&lt;/code&gt; is called, the transaction interceptor kicks in through the AOP proxying mechanism, and it starts a new transaction by using the custom &lt;code&gt;KafkaTransactionManager&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;When the transaction manager begins the transaction, the resource used by the transaction manager - the transactional resource holder (AKA, producer obtained from the producer factory) - is bound to the transaction.&lt;/li&gt;
&lt;li&gt;When the method calls the &lt;code&gt;StreamBridge#send&lt;/code&gt; method, the underlying &lt;code&gt;KafkaTemplate&lt;/code&gt; will use the same transactional resource created by the custom &lt;code&gt;KafkaTransactionManager&lt;/code&gt;. Since a transaction is already in progress, it does not start another transaction, but the publishing occurs on the same transactional producer.&lt;/li&gt;
&lt;li&gt;As it calls more &lt;code&gt;send&lt;/code&gt; methods, it will not start new transactions. Instead, it publishes via the same producer resource used in the original transaction.&lt;/li&gt;
&lt;li&gt;When the method exits, the interceptor asks the transaction manager to commit the transaction if there is no error. If any of the send operations or anything else in the method throws an exception, the interceptor asks the transaction manager to roll back the transaction. These calls eventually hit the &lt;code&gt;KafkaResourceHolder&lt;/code&gt; &lt;strong&gt;commit&lt;/strong&gt; or &lt;strong&gt;rollback&lt;/strong&gt; methods, which calls the Kafka producer to &lt;strong&gt;commit&lt;/strong&gt; or &lt;strong&gt;rollback&lt;/strong&gt; the transaction.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since we only have one custom &lt;code&gt;KafkaTransactionManager&lt;/code&gt; bean in our example, we can simply use the &lt;code&gt;Transactional&lt;/code&gt; annotation as is. On the other hand,  if we had multiple custom &lt;code&gt;KafkaTransactionManager&lt;/code&gt; beans, we would have to qualify the &lt;code&gt;@Transactional&lt;/code&gt; annotation with the correct bean name.&lt;/p&gt;
&lt;h2 id=&quot;what-if-we-run-the-app-without-the-custom-kafkatransactionmanager&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#what-if-we-run-the-app-without-the-custom-kafkatransactionmanager&quot; aria-label=&quot;what if we run the app without the custom kafkatransactionmanager permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What if we run the app without the custom KafkaTransactionManager?&lt;/h2&gt;
&lt;p&gt;If we remove the custom &lt;code&gt;KafkaTransactionManager&lt;/code&gt; and run this application, you can see that it creates five individual transactions, not a single transaction. If you enable &lt;code&gt;TRACE&lt;/code&gt; logging, you can see five sequences of &lt;strong&gt;beginTransaction¡¦commitTransaction&lt;/strong&gt; in the logs.&lt;/p&gt;
&lt;p&gt;You can verify this behavior by writing a transactional consumer Spring Cloud Stream application and setting its isolation level to &lt;code&gt;read_committed&lt;/code&gt;. You can do so by using the &lt;code&gt;spring.cloud.stream.kafka.binder.configuration.isolation.level&lt;/code&gt; property and setting its value to &lt;code&gt;read_committed&lt;/code&gt;. For testing purposes, add a &lt;code&gt;Thread.sleep&lt;/code&gt; or another wait mechanism to simulate the behavior after each &lt;code&gt;StreamBridge#send&lt;/code&gt; in the for loop. You can see that, as soon as each &lt;code&gt;send&lt;/code&gt; method call returns, regardless of the wait, the consumer receives data, thus proving that not a single transaction carried out the entire operation, rather each &lt;code&gt;send&lt;/code&gt; occurred in its own transaction.&lt;/p&gt;
&lt;p&gt;We see individual transactions for each send because the &lt;code&gt;Transactional&lt;/code&gt; annotation does not do what we expect it to do. The &lt;code&gt;Transactional&lt;/code&gt; annotation works only if there is a transaction manager bean available and its producer factory is the same one used by the binder.&lt;/p&gt;
&lt;p&gt;Spring Boot auto-configures a &lt;code&gt;KafkaTransactionManager&lt;/code&gt; if it detects the &lt;code&gt;transaction-id-prefix&lt;/code&gt; property in the configuration through &lt;code&gt;spring.kafka.producer.transaction-id-prefix&lt;/code&gt;. However, since we are in a Spring Cloud Stream context, we must use &lt;code&gt;spring.cloud.stream.kafka.binder.transaction.transaction-id-prefix&lt;/code&gt;, since this is how we signal the framework to create an internal transaction manager for the binder and the associated transactional producer factory. What if we provide the proper &lt;code&gt;spring.kafka&lt;/code&gt; prefix so that Spring Boot auto-configures a &lt;code&gt;KakaTransactionManager&lt;/code&gt; for us? Although that is very tempting, it does not work, as the auto-configured transaction manager uses a different producer factory from the one that the binder uses. Thus, we must provide a custom &lt;code&gt;KafkaTransactionManager&lt;/code&gt; that uses the same producer factory the binder uses. This is precisely what we did above.&lt;/p&gt;
&lt;p&gt;In the next part of this blog series, we will learn how to synchronize with external transaction managers for both producer and consumer-initiated transactions.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[A Bootiful Podcast: Spring AI lead Dr. Mark Pollack]]></title><link>https://spring.io/blog/2023/09/28/a-bootiful-podcast-spring-ai-lead-dr-mark-pollack</link><guid isPermaLink="true">https://spring.io/blog/2023/09/28/a-bootiful-podcast-spring-ai-lead-dr-mark-pollack</guid><dc:creator><![CDATA[Josh Long]]></dc:creator><pubDate>Thu, 28 Sep 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Hi, Spring fans! In this episode I talk to Dr. Mark Pollack, lead of the new Spring AI project. This episode was recorded live at SpringOne at VMware Explore 2023, in Las Vegas.&lt;/p&gt;
&lt;iframe title=&quot;Spring AI lead Dr. Mark Pollack&quot; allowtransparency=&quot;true&quot; height=&quot;150&quot; width=&quot;100%&quot; style=&quot;border: none; min-width: min(100%, 430px);height:150px;&quot; scrolling=&quot;no&quot; data-name=&quot;pb-iframe-player&quot; src=&quot;https://www.podbean.com/player-v2/?i=ppwr4-14b84f8-pb&amp;from=pb6admin&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Arial&amp;skin=1&amp;font-color=&amp;logo_link=episode_page&amp;btn-skin=7&quot; loading=&quot;lazy&quot;&gt;&lt;/iframe&gt;</content:encoded></item><item><title><![CDATA[Introduction to Transactions in Spring Cloud Stream Kafka Applications]]></title><link>https://spring.io/blog/2023/09/27/introduction-to-transactions-in-spring-cloud-stream-kafka-applications</link><guid isPermaLink="true">https://spring.io/blog/2023/09/27/introduction-to-transactions-in-spring-cloud-stream-kafka-applications</guid><dc:creator><![CDATA[Soby Chacko]]></dc:creator><pubDate>Wed, 27 Sep 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;We are starting a new blog series that focuses on working with transactions in Spring Cloud Stream Kafka applications. This blog series covers many low-level details of writing transactional applications with Spring Cloud Stream and Apache Kafka. By the end of this blog series, we hope to give you enough information about writing transactional Spring Cloud Stream Kafka applications for various business use cases.&lt;/p&gt;
&lt;h2 id=&quot;basic-building-blocks&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#basic-building-blocks&quot; aria-label=&quot;basic building blocks permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Basic Building Blocks&lt;/h2&gt;
&lt;p&gt;The foundational support for transactions in Spring Cloud Stream Kafka applications primarily comes from Apache Kafka itself and the Spring for Apache Kafka library. However, this blog series is about using this support specifically with Spring Cloud Stream. If you are familiar with how transactions work in Apache Kafka and how Spring for Apache Kafka makes it possible to use it in a Spring-friendly way, this series will feel like home turf.&lt;/p&gt;
&lt;p&gt;While Apache Kafka provides the foundational transaction support, the Spring for Apache Kafka (AKA Spring Kafka) library extends this support on the Spring side to make it more natural for Spring developers to use it by relying on the traditional transactional support available in Spring Framework. The Kafka binder in Spring Cloud Stream further builds upon this support from Spring for Apache Kafka, making it possible to use that same support in Spring Cloud Stream Kafka applications. In this first part of the blog series, we briefly introduce Kafka transactions, some use case analysis where it becomes helpful to rely on transactions, and the transactional building blocks in Apache Kafka and the Spring ecosystem.&lt;/p&gt;
&lt;p&gt;There are many use cases, in which, publishing, consuming, and processing records transactionally in Apache Kafka becomes necessary. When producing records transactionally in a producer-initiated application or a process that implements a consume-process-produce pattern transactionally, they are written to Kafka atomically. If something goes wrong, the whole process gets rolled back, and the transaction is not committed. One thing to remember is that, unlike a relational database that supports transactions, where no records persist when such transaction rollback occurs, Apache Kafka still publishes the records to the topic partition. This behavior is due to the fundamental append-only immutable log-based architecture of Apache Kafka, which does not allow any record modifications, such as removing the records after adding them to the record log. One might wonder what the benefit of using transactions is, since the records may be published to the topic partition when a transaction gets aborted, potentially causing consumers to see them. However, a consumer with the proper &lt;a href=&quot;https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#isolation-level&quot;&gt;isolation levels&lt;/a&gt; never sees the rolled-back records, even though the records from the rolled-back transaction are in the topic partition. Thus, from an end-to-end standpoint, the whole process is guaranteed to be fully transactional.&lt;/p&gt;
&lt;h2 id=&quot;transactional-use-cases&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#transactional-use-cases&quot; aria-label=&quot;transactional use cases permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transactional Use Cases&lt;/h2&gt;
&lt;p&gt;Transactions usually add significant overhead in Kafka applications. When using transactions in Apache Kafka, each record must add special transaction logs to the record, send a transaction marker to a special transaction state topic, and so on. All these steps take time and space, increasing the overall latency. Therefore, each application must carefully examine the need for transactional support by analyzing the use cases.&lt;/p&gt;
&lt;p&gt;Transactions provide a way to primarily safeguard the data to provide &lt;a href=&quot;https://en.wikipedia.org/wiki/ACID&quot;&gt;ACID&lt;/a&gt; capabilities. It ensures data integrity by providing atomicity, consistency, data isolation, and durability.&lt;/p&gt;
&lt;p&gt;There are several mission-critical use cases in today¡¯s enterprises where using transactions and relying on the ACID semantics they bring is highly desirable. There is no simple, straightforward answer regarding when you want to use transactions and justify the overhead it brings. You have to look at the application and evaluate what is at stake. The usual canonical example of transactions is anything that needs to deal with financial data. Bob sends money to Alice, an action that debits from Bob¡¯s account, and Alice gets credited. If anything goes wrong in this process, the whole thing gets rolled back as if nothing happened, as we do not want the flow to be in a haphazard state. If the process debits from Bob¡¯s account, but Alice is not credited (or vice-versa), that is a problem. From Apache Kafka perspective, we have a few things going on here. First, a message comes to a Kafka processor to debit from Bob¡¯s account and the receiver&apos;s information. The processor processes the information and then sends a message to another topic, indicating that a debit occurred from Bob¡¯s account. After this, another message indicates that Alice is now credited. The various actions in this process require complex coordination to ensure that everything happens as expected. Any time we have multiple related events like these, transactions may help ensure data integrity and provide the ACID semantics. In this example, a single event does not have much meaning standalone, but they all combine to form the entire flow and require transactionality to ensure data integrity.&lt;/p&gt;
&lt;p&gt;If we want to generalize this pattern, we can say that any time we have a consume-process-publish pattern that is mission critical, where, if one component fails, the whole processor needs to act as if it didn¡¯t happen, using transactions is a potential solution to look at.&lt;/p&gt;
&lt;h4 id=&quot;more-high-level-examples-from-other-domains&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#more-high-level-examples-from-other-domains&quot; aria-label=&quot;more high level examples from other domains permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;More high-level examples from other domains&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Imagine an airline reservation system that needs to publish information about a reservation with multiple legs. If, for any reason, the system cannot publish the whole reservation, it needs to abort the process and start over.&lt;/li&gt;
&lt;li&gt;A brokerage that sends requests that contain multiple buy orders to send to a clearing house. Suppose the process cannot publish the individual orders as a single atomic unit to the messaging system from which the clearing house consumes. In that case, the brokerage must resend the order.&lt;/li&gt;
&lt;li&gt;A medical billing system that sends patient test data to an insurance company must publish various related tests from a patient to the messaging system.&lt;/li&gt;
&lt;li&gt;An online gaming system needs to track players&apos; positions in a game and send them to a centralized server transactionally to ensure that all the players see the correct coordinates, not partially updated locations.&lt;/li&gt;
&lt;li&gt;An inventory restocking system at a retailer needs to send information about various related product statuses as a single atomic unit.&lt;/li&gt;
&lt;li&gt;An online e-commerce ordering system that publishes order details (such as order entries, account holder information, shipping information, and so on) within a single atomic aggregate operation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;synchronizing-with-external-databases&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#synchronizing-with-external-databases&quot; aria-label=&quot;synchronizing with external databases permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Synchronizing with External Databases&lt;/h4&gt;
&lt;p&gt;Another class of use cases in which transactions become handy is when you have to synchronize with other transactional systems. In addition to publishing to Kafka, assume that you must persist the records or some derived information in a relational database, all within a single atomic operation. If one system fails to send the data, we must roll back. If you have only a single record each time to publish to Kafka and nothing else and no other related operations, you do not need to use transactions, as we will see in the next part of this blog series. However, even if you publish to a Kafka topic only once but use a relational database operation as part of the same process, using transactions becomes necessary to ensure data integrity.&lt;/p&gt;
&lt;h4 id=&quot;publishing-to-multiple-kafka-topics&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#publishing-to-multiple-kafka-topics&quot; aria-label=&quot;publishing to multiple kafka topics permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Publishing to Multiple Kafka Topics&lt;/h4&gt;
&lt;p&gt;Another use case for transactions in a producer-only application is publishing to multiple Kafka topics. Assume you have some business-critical data in the form of a critical notification (such as an order detail) you wish to publish to multiple Kafka topics, some part of the order detail to an order topic, and another to a shipping topic. In that case, we can use transactions to ensure end-to-end data integrity.&lt;/p&gt;
&lt;h4 id=&quot;generalizing-the-transactional-use-cases-above&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#generalizing-the-transactional-use-cases-above&quot; aria-label=&quot;generalizing the transactional use cases above permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Generalizing the Transactional Use Cases Above&lt;/h4&gt;
&lt;p&gt;The above set of use cases is a non-exhaustive list where transactions are necessary. Many other use cases, not that different from the general thrust of the ones we looked at, exist in today¡¯s enterprises from various domains that require transactional processing in messaging systems.&lt;/p&gt;
&lt;p&gt;The following list summarizes generalized use cases where transactions in Apache Kafka can be helpful:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consume-process-publish systems where it needs to publish records as a single atomic unit and provide an exactly-once-semantics delivery guarantee.&lt;/li&gt;
&lt;li&gt;Multiple publishing events that are related and do not make sense individually.&lt;/li&gt;
&lt;li&gt;Publishing data to multiple topics as a single atomic unit.&lt;/li&gt;
&lt;li&gt;Synchronizing with external transaction managers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a pictorial representation of all these various situations. It covers the scenarios we considered above, such as the consume-process-produce, multiple producers, synchronizing with external transactions, and others. A processor consumes data from an inbound topic, executes the business logic, persists some information to a database system, and publishes to multiple Kafka topics.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/spring-cloud/spring-cloud-stream/raw/gh-pages/images/scst-kafka-txn-overview.png&quot; alt=&quot;scst-kafka-txn-overview&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;transactions-in-apache-kafka&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#transactions-in-apache-kafka&quot; aria-label=&quot;transactions in apache kafka permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transactions in Apache Kafka&lt;/h2&gt;
&lt;p&gt;There is plenty of literature available to study the low-level details of how transactions work in Apache Kafka, and &lt;a href=&quot;https://www.confluent.io/blog/transactions-apache-kafka&quot;&gt;here is an article&lt;/a&gt; that can give an introduction to those details. However, briefly seeing the Kafka client APIs for achieving transactionality from a very high-level is still worthwhile. One thing to note is that, when it comes to plain consumers, there is no such thing as a transactional consumer in Kafka, but there are transaction-aware consumers. Consumers achieve this transactional awareness by setting the isolation level. By default, a consumer in Kafka sees all records, even the uncommitted records, by an upstream producer because the default isolation level is &lt;strong&gt;read_uncommitted&lt;/strong&gt; in a Kafka consumer. A Kafka consumer must use the isolation level of &lt;strong&gt;read_committed&lt;/strong&gt; to provide end-to-end transactional semantics. We will see how we can accomplish this in Spring Cloud Stream in the upcoming sections of this blog series.&lt;/p&gt;
&lt;p&gt;On the producer side, there are a few API methods that an application relies on from the Kafka client. Let¡¯s take a look at the important ones.&lt;/p&gt;
&lt;p&gt;To make an application transactional, the Kafka client requires a transaction ID. The applications provide it through a Kafka producer property called &lt;strong&gt;transactional.id&lt;/strong&gt;, which the transaction coordinator uses to initiate the transaction by registering it. The transaction coordinator uses this ID to track all aspects of the transaction, such as initializing it, ongoing progress, commit, etc.&lt;/p&gt;
&lt;p&gt;The following list summarizes the critical transaction-related producer API methods.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Producer#initTransactions()&lt;/strong&gt; - Called once per producer to initiate transaction support. Initializes the Kafka transaction.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Producer#beginTransaction()&lt;/strong&gt; - Begins the transaction before sending the record.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Producer#sendOffsetsToTransaction()&lt;/strong&gt; - Sends the consumed record offset to the transaction.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Producer#commitTransaction()&lt;/strong&gt; - Commits the transaction.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Producer#abortTransaction()&lt;/strong&gt; - Aborts the transaction.&lt;/p&gt;
&lt;p&gt;Before sending a record, we need to initialize and begin the transaction. Then, it carries on with data processing. If we consumed a record to do this publishing, we must send the consumed record¡¯s offset to the transaction using the producer. After this, the transaction commit or abort operation can continue (commitTransaction or abortTransaction). When we call the commitTransaction method, that is when, exactly, the offsets are atomically sent to the consumer_offsets topic by the Kafka client.&lt;/p&gt;
&lt;h2 id=&quot;transaction-support-in-spring-for-apache-kafka&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#transaction-support-in-spring-for-apache-kafka&quot; aria-label=&quot;transaction support in spring for apache kafka permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Transaction Support in Spring for Apache Kafka&lt;/h2&gt;
&lt;p&gt;When using a framework like Spring for Apache Kafka or Spring Cloud Stream Kafka binder that relies on it, they bring the benefit of allowing applications to focus primarily on the business logic since the frameworks handle the low-level boilerplate transactional sequence that we saw above.
It would be beneficial to use Spring for Apache Kafka or another framework (such as Spring Cloud Stream that uses it) because it allows us not worrying about writing the low-level boilerplate sequence (described above) to ensure that all the transactional steps succeed. As you can imagine, there are many moving parts here, and if you omit a step or not doing a step as per the expectations, it could make the application error-prone. In the case of Spring, the frameworks we mentioned handle them on behalf of the application developer. Let¡¯s briefly see how it does that.&lt;/p&gt;
&lt;p&gt;The Spring for Apache Kafka framework hides all these low-level details by providing a consistent transactional programming model familiar to Spring developers. The result is that the applications, when using Spring for Apache Kafka or another framework such as Spring Cloud Stream, can simply focus on the application¡¯s business logic rather than deal with complex low-level transactional-related matters.&lt;/p&gt;
&lt;h4 id=&quot;kafkatransactionmanager&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#kafkatransactionmanager&quot; aria-label=&quot;kafkatransactionmanager permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;KafkaTransactionManager&lt;/h4&gt;
&lt;p&gt;How does Spring for Apache Kafka provide this consistent transactional programming model? The short answer is that Spring developers have traditionally used Transactional annotation or programmatic approaches, such as using a TransactionTemplate directly in the applications to create local transactions. These mechanisms need a transaction manager implementation to drive the transactional aspects. Spring for Apache Kafka provides a transaction manager implementation. &lt;strong&gt;KafkaTransactionManager&lt;/strong&gt; is an implementation of the &lt;strong&gt;PlatformTransactionManager&lt;/strong&gt; in Spring Framework. You can use this transaction manager along with the Transactional annotation or in local transactions by using a TransactionTemplate. KafkaTransactionManager uses a producer factory to create a Kafka producer and provides APIs to begin, commit, and roll back transactions.&lt;/p&gt;
&lt;h4 id=&quot;kafkaresourceholder&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#kafkaresourceholder&quot; aria-label=&quot;kafkaresourceholder permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;KafkaResourceHolder&lt;/h4&gt;
&lt;p&gt;Spring for Apache Kafka also provides a &lt;strong&gt;KafkaResourceHolder&lt;/strong&gt; that holds the Kafka producer resource. KafkaTemplate in Spring for Apache Kafka triggers the binding of a KafkaResourceHolder on the current thread for a given producer factory. In the case of a consumer-initiated transaction, the message listener container does this binding, and the producer factory is the same as that used by the KafkaTransactionManager. This way, the transaction uses the same transactional producer for all publishing needs.&lt;/p&gt;
&lt;p&gt;In addition to the above components, Spring for Apache Kafka provides other utilities for dealing with transactional-related concerns. As it becomes necessary when we go through the following sections of this series, we will see some of them.&lt;/p&gt;
&lt;p&gt;In part 2 of this blog series, we will move on to more practical implementation details of using transactions in Spring Cloud Stream applications.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[This Week in Spring - September 26th, 2023]]></title><link>https://spring.io/blog/2023/09/26/this-week-in-spring-september-26th-2023</link><guid isPermaLink="true">https://spring.io/blog/2023/09/26/this-week-in-spring-september-26th-2023</guid><dc:creator><![CDATA[Josh Long]]></dc:creator><pubDate>Tue, 26 Sep 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! How are you? It&apos;s September 26th, 2023, and I am in sunny Singapore for SpringOne at VMWare Explore Singapore. If you&apos;re around, don&apos;t forget to say hi!&lt;/p&gt;
&lt;p&gt;It&apos;s gonna be a fun and busy week in Singapore, and then next week I&apos;m off to Antwerp, Belgium, for the amazing Devoxx BE 2023. Then, I&apos;m off to Morocco, for Devoxx MA 2023. Then, I&apos;m off to Amsterdam for SpringOne Tour Amsterdam. If you&apos;re in any of these places, do not hesitate to reach out and say hi! I&apos;d love to chat! And with that, we&apos;ve got a ton of things to cover so let&apos;s dive right into it!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Java 21 is here, and I wrote a huuuuge explainer about all the new features in this blog here: &lt;a href=&quot;https://spring.io/blog/2023/09/20/hello-java-21&quot;&gt;Hello, Java 21&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If you want to watch your knowledge instead of read it, &lt;a href=&quot;https://www.youtube.com/watch?v=8VJ_dSdV3pY&quot;&gt;you might watch this video instead&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Want to learn more about one key dimension of the new features in Java 21? Check out this article from Java language architect Brian Goetz from 2022: &lt;a href=&quot;https://www.infoq.com/articles/data-oriented-programming-java/&quot;&gt;Data Oriented Programming in Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://cloud.google.com/blog/products/application-development/develop-and-test-spring-boot-applications-consistently/&quot;&gt;How Google Cloud emulators and Testcontainers speed up development | Google Cloud Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://twitter.com/juliendubois/status/1705305573627965499&quot;&gt;Want to use Oracle OpenJDK 21 in Github Actions? Julien Dubois has you sorted&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://spring.io/blog/2023/09/22/simplified-event-externalization-with-spring-modulith&quot;&gt;Simplified Event Externalization with Spring Modulith&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://spring.io/blog/2023/09/21/spring-cloud-dataflow-2-11-0-released&quot;&gt;Spring Cloud Dataflow 2.11.0 Released&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://m.youtube.com/watch?si=npRfyttagbPKwcPb&amp;#x26;v=430YOyMNjhs&amp;#x26;feature=youtu.be&quot;&gt;Spring Modulith ? A Deep Dive (Workshop) - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://spring.io/blog/2023/09/19/spring-for-graphql-1-0-5-1-1-6-1-2-3-released&quot;&gt;Spring for GraphQL 1.0.5, 1.1.6, 1.2.3 released&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://kubernetes.io/blog/2023/09/25/kubeadm-use-etcd-learner-mode/&quot;&gt;Blog: kubeadm: Use etcd Learner to Join a Control Plane Node Safely&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Paketo Buildpacks Bionic End Of Support]]></title><link>https://spring.io/blog/2023/09/22/paketo-buildpacks-bionic-end-of-support</link><guid isPermaLink="true">https://spring.io/blog/2023/09/22/paketo-buildpacks-bionic-end-of-support</guid><dc:creator><![CDATA[Scott Frederick]]></dc:creator><pubDate>Fri, 22 Sep 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The Spring Boot plugins for Maven and Gradle provide the ability to &lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#container-images.buildpacks&quot;&gt;build Docker images using Cloud Native Buildpacks&lt;/a&gt;. By default, Spring Boot uses the CNB builders provided by the &lt;a href=&quot;https://paketo.io/&quot;&gt;Paketo Buildpacks&lt;/a&gt; project.&lt;/p&gt;
&lt;h1 id=&quot;whats-changed&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#whats-changed&quot; aria-label=&quot;whats changed permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What&apos;s Changed&lt;/h1&gt;
&lt;p&gt;The Paketo Buildpacks project has announced that Ubuntu 18.04 Bionic-based builders are no longer supported, in favor of Ubuntu 22.04 Jammy-based builders. See the &lt;a href=&quot;https://blog.paketo.io/posts/bionic-eos/&quot;&gt;Paketo announcement&lt;/a&gt; for more details on the builders that are affected by this change.&lt;/p&gt;
&lt;p&gt;The Maven and Gradle plugins for Spring Boot versions 3.1 and earlier use the Bionic Base Builder by default when building images to run applications on a JVM, and the Bionic Tiny Builder by default when building images from native executables using GraalVM. Paketo Jammy builders will be the default starting with Spring Boot 3.2.&lt;/p&gt;
&lt;p&gt;Users of Spring Boot 3.1 and earlier should make changes to their build configurations to migrate to the Paketo Jammy builders in order to receive regular updates to buildpacks and the dependencies that buildpacks install.&lt;/p&gt;
&lt;h1 id=&quot;migration&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#migration&quot; aria-label=&quot;migration permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Migration&lt;/h1&gt;
&lt;h2 id=&quot;maven&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#maven&quot; aria-label=&quot;maven permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Maven&lt;/h2&gt;
&lt;p&gt;To use the Paketo Jammy builder in a Spring Boot build using Maven, the builder should be configured as shown in this example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;#x3C;project&gt;
    &amp;#x3C;build&gt;
        &amp;#x3C;plugins&gt;
            &amp;#x3C;plugin&gt;
                &amp;#x3C;groupId&gt;org.springframework.boot&amp;#x3C;/groupId&gt;
                &amp;#x3C;artifactId&gt;spring-boot-maven-plugin&amp;#x3C;/artifactId&gt;
                &amp;#x3C;configuration&gt;
                    &amp;#x3C;image&gt;
                        &amp;#x3C;builder&gt;paketobuildpacks/builder-jammy-base:latest&amp;#x3C;/builder&gt;
                    &amp;#x3C;/image&gt;
                &amp;#x3C;/configuration&gt;
            &amp;#x3C;/plugin&gt;
        &amp;#x3C;/plugins&gt;
    &amp;#x3C;/build&gt;
&amp;#x3C;/project&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See the Spring Boot Maven plugin &lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/maven-plugin/reference/htmlsingle/#build-image.customization&quot;&gt;documentation&lt;/a&gt; for more information on configuring the plugin.&lt;/p&gt;
&lt;h2 id=&quot;gradle&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#gradle&quot; aria-label=&quot;gradle permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Gradle&lt;/h2&gt;
&lt;p&gt;When using Gradle with Groovy, the builder should be configured as shown in this example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-groovy&quot;&gt;tasks.named(&quot;bootBuildImage&quot;) {
	builder = &quot;paketobuildpacks/builder-jammy-base:latest&quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When using Gradle with Kotlin, the builder should be configured as shown in this example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-kotlin&quot;&gt;tasks.named&amp;#x3C;BootBuildImage&gt;(&quot;bootBuildImage&quot;) {
	builder.set(&quot;paketobuildpacks/builder-jammy-base:latest&quot;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See the Spring Boot Gradle plugin &lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/gradle-plugin/reference/htmlsingle/#build-image.customization&quot;&gt;documentation&lt;/a&gt; for more information on configuring the plugin.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Simplified Event Externalization with Spring Modulith]]></title><link>https://spring.io/blog/2023/09/22/simplified-event-externalization-with-spring-modulith</link><guid isPermaLink="true">https://spring.io/blog/2023/09/22/simplified-event-externalization-with-spring-modulith</guid><dc:creator><![CDATA[Oliver Drotbohm]]></dc:creator><pubDate>Fri, 22 Sep 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Transactional service methods are a common pattern in Spring applications. These methods trigger a state transition important to the business. This usually involves a core domain abstraction, such as an aggregate and its corresponding repository. A stereotypical example of such an arrangement might look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Service
@RequiredArgsConstructor
class OrderManagement {

  private final OrderRepository orders;

  @Transactional
  Order complete(Order order) {
     return orders.save(order.complete());
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As state transitions like these might be interesting to third parties, we might want to involve a message broker to publish a message for general distribution across other systems. A naive approach to implement this would be to hide that kind of interaction in another Spring service, inject that into our primary bean and invoke a method that would ultimately interact with the broker.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Service
@RequiredArgsConstructor
class OrderManagement {

  private final OrderRepository orders;
  private final MessageSender sender;

  @Transactional
  Order complete(Order order) {

     var result = orders.save(order.complete());

     sender.publishMessage(¡¦);

     return result;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;problems&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#problems&quot; aria-label=&quot;problems permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Problems&lt;/h2&gt;
&lt;p&gt;Unfortunately, this approach suffers from a variety of problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;As the method runs within a transaction, it has already acquired a database connection. Interaction with other infrastructure is costly and, thus, likely significantly extends the length of the transaction, preventing the connection from being returned early, which might lead to connection pool saturation and, thus, poor performance.&lt;/li&gt;
&lt;li&gt;While we have elegantly wrapped the interaction with the broker behind a nice-looking facade, our &lt;code&gt;completeOrder(¡¦)&lt;/code&gt; method is now susceptible to more infrastructure problems. Failing to access the broker rolls back the transactions and prevent orders from completion. Our system might be technically available but entirely unable to do anything useful due to a downstream infrastructure problem.&lt;/li&gt;
&lt;li&gt;Lastly, we have created a consistency issue in case the message publication succeeds but the database transaction ends up rolling back eventually.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A common pattern to solve these problems is publishing an application event from the service, which, at first glance, doesn&apos;t look too different from what we had laid out before.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Service
@RequiredArgsConstructor
class OrderManagement {

  private final OrderRepository orders;
  private final ApplicationEventPublisher events; 

  @Transactional
  Order complete(Order order) {

     var result = orders.save(order.complete());

     events.publishEvent(
         new OrderCompleted(result.getId(), result.getCustomerId()));

     return result;
  }

  record OrderCompleted(OrderId orderId, CustomerId customerId) {}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The primary difference here is that the event published is a simple object handed around &lt;em&gt;within&lt;/em&gt; the JVM in the first place. The actual interaction with the broker would then be implemented in an &lt;code&gt;@Async&lt;/code&gt; &lt;code&gt;@TransactionalEventListener&lt;/code&gt;. By default, such a listener will be invoked after the original business transaction has committed, which resolves issue 3. Marking the listener with &lt;code&gt;@Async&lt;/code&gt; causes the event handling being executed on a separate thread, which in turn solves problem 1.&lt;/p&gt;
&lt;h2 id=&quot;spring-modulith-event-externalization&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#spring-modulith-event-externalization&quot; aria-label=&quot;spring modulith event externalization permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Spring Modulith Event Externalization&lt;/h2&gt;
&lt;p&gt;The implementation of the listener is a rather mundane exercise: we have to select a broker-specific client (Spring Kafka, Spring AMQP, JMS, and others), marshal the event, determine a routing target, and (optional and depending on the broker) a routing key. Spring Modulith 1.1 M1 ships such an integration out of the box. To use it with Kafka, for example, you would add the corresponding artifact to your project¡¯s class path:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;#x3C;dependency&gt;
  &amp;#x3C;groupId&gt;org.springframework.modulith&amp;#x3C;/groupId&gt;
  &amp;#x3C;artifactId&gt;spring-modulith-events-api&amp;#x3C;/artifactId&gt;
&amp;#x3C;/dependency&gt;
&amp;#x3C;dependency&gt;
  &amp;#x3C;groupId&gt;org.springframework.modulith&amp;#x3C;/groupId&gt;
  &amp;#x3C;artifactId&gt;spring-modulith-events-kafka&amp;#x3C;/artifactId&gt;
  &amp;#x3C;scope&gt;runtime&amp;#x3C;/scope&gt;
&amp;#x3C;/dependency&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The presence of the latter JAR registers a listener, as described above. To get an application event transparently published to a broker, you can annotate it with the &lt;code&gt;@Externalized&lt;/code&gt; annotation provided by either Spring Modulith&apos;s (the first JAR) or jMolecules&apos; (not shown), like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import org.springframework.modulith.events.Externalized;

@Externalized(&quot;orders.OrderCompleted::#{customerId()}&quot;)
record OrderCompleted(OrderId orderId, CustomerId customerId) {}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The presence of the annotation triggers instances of that class being selected for publication. We have defined &lt;code&gt;orders.OrderCompleted&lt;/code&gt; as a routing target. The SpEL expression, &lt;code&gt;#{customerId()}&lt;/code&gt;, selects the accessor method to be invoked on the event to produce a routing key, which triggers the correct partition assignment. If you prefer describing event selection and routing in code, check out how to use &lt;a href=&quot;https://docs.spring.io/spring-modulith/reference/1.1/events.html#externalization.api&quot;&gt;&lt;code&gt;EventExternalizationConfiguration&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;error-scenarios&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#error-scenarios&quot; aria-label=&quot;error scenarios permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Error Scenarios&lt;/h2&gt;
&lt;p&gt;This is all pretty convenient, and we have elegantly solved two of our three problems already. But what about the error scenario? What if the message publication fails? The original business transaction has already committed, but we have now lost the internal event publication. Fortunately, that case is already solved by Spring Modulith&apos;s &lt;a href=&quot;https://docs.spring.io/spring-modulith/reference/1.1/events.html#publication-registry&quot;&gt;Event Publication Registry&lt;/a&gt;. It creates a registry entry for every transactional event listener interested in an event being published and marks that entry completed only if the listener succeeds. Failing to send the message to the broker results in the entry staying around, being subject to resubmission attempts later.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#summary&quot; aria-label=&quot;summary permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Summary&lt;/h2&gt;
&lt;p&gt;Interacting with third infrastructure within a primary business transaction should be avoided for performance, reliability, and consistency reasons. Spring Modulith 1.1 allows easily publishing application events to message brokers by marking event types for externalization and defining routing targets and keys. For more information, refer to the &lt;a href=&quot;https://docs.spring.io/spring-modulith/reference/1.1/events.html#externalization&quot;&gt;reference documentation&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Spring Modulith 1.1 M1 and 1.0.1 released]]></title><link>https://spring.io/blog/2023/09/21/spring-modulith-1-1-m1-and-1-0-1-released</link><guid isPermaLink="true">https://spring.io/blog/2023/09/21/spring-modulith-1-1-m1-and-1-0-1-released</guid><dc:creator><![CDATA[Oliver Drotbohm]]></dc:creator><pubDate>Thu, 21 Sep 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;On behalf of the community, I am happy to announce the release of Spring Modulith 1.1 M1 and 1.0.1. While the latter primarily ships minor bug fixes, the former packages quite a few new features, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support to externalize application events into Kafka, AMQP and JMS &lt;a href=&quot;https://github.com/spring-projects/spring-modulith/issues/248&quot;&gt;GH-248&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;APIs to access completed and incomplete event publications &lt;a href=&quot;https://github.com/spring-projects/spring-modulith/issues/294&quot;&gt;GH-294&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support for Neo4j as persistence store to back the Event Publication Registry &lt;a href=&quot;https://github.com/spring-projects/spring-modulith/issues/301&quot;&gt;GH-301&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will have a blog post elaborating on the former coming soon. Feel free to check out the &lt;a href=&quot;https://github.com/spring-projects/spring-modulith/releases/tag/1.1.0-M1&quot;&gt;full change log&lt;/a&gt; and &lt;a href=&quot;https://docs.spring.io/spring-modulith/reference/1.1/index.html&quot;&gt;revamped reference documentation&lt;/a&gt; in the meantime. Thanks to everyone who contributed!&lt;/p&gt;</content:encoded></item></channel></rss>